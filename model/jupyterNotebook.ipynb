{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c13844f",
   "metadata": {},
   "source": [
    "# DeepFake Face Detector Training Notebook\n",
    "This notebook trains a computer to spot fake images using a Vision Transformer (ViT) model.\n",
    "\n",
    "## 1. Importing Libraries\n",
    "Python makes it easy to use powerful libraries for machine learning and AI. Here, we import:\n",
    "- `os`: For file and directory operations.\n",
    "- `torch`: The core library for deep learning in Python (PyTorch).\n",
    "- `transformers`: Provides pre-trained models and tools for AI tasks.\n",
    "- `datasets`: For loading and managing datasets.\n",
    "- `sklearn.metrics`: For evaluating model performance.\n",
    "- `PIL.Image`: For image processing.\n",
    "\n",
    "These libraries are widely used in the AI community and make complex tasks much simpler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de40b919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoImageProcessor,\n",
    "    ViTForImageClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d791d94",
   "metadata": {},
   "source": [
    "## Configuration & Model Selection\n",
    "Set up the model checkpoint, image size, and data paths.\n",
    "\n",
    "## 2. Configuration & Model Selection\n",
    "We define important settings:\n",
    "- **Model Checkpoint**: Specifies which pre-trained AI model to use (Vision Transformer).\n",
    "- **Image Resolution**: Images are resized to 224x224 pixels, matching the model's requirements.\n",
    "- **Data Path**: Location of the dataset on disk.\n",
    "- **Output Directory**: Where results and trained models will be saved.\n",
    "\n",
    "This step shows how Python variables are used to configure experiments and control workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8748a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT = 'google/vit-base-patch16-224-in21k'\n",
    "TARGET_RESOLUTION = 224\n",
    "DATA_PATH = 'E:/data_02'  # Path to dataset with 'train', 'validation', 'test' folders\n",
    "OUTPUT_DIR = 'E:/vit_in21k_output_02'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2045f62",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "Load the dataset from the specified folder.\n",
    "\n",
    "## 3. Loading the Dataset\n",
    "We use the `datasets` library to load images from folders. Python makes it easy to:\n",
    "- Automatically detect training, validation, and test sets.\n",
    "- Organize data for machine learning tasks.\n",
    "\n",
    "This step demonstrates how AI projects start with data collection and preparation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf60b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Loading data from: {DATA_PATH}')\n",
    "dataset = load_dataset('imagefolder', data_dir=DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fec83b",
   "metadata": {},
   "source": [
    "## Prepare Data\n",
    "Get label names and mappings.\n",
    "\n",
    "## 4. Label Mapping\n",
    "Machine learning models need numbers, not words. We:\n",
    "- Extract label names (like 'real', 'fake').\n",
    "- Convert them to numbers so the model can understand them.\n",
    "\n",
    "This is a key step in supervised learning, where each example has a known answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ad5337",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = dataset['train'].features['label'].names\n",
    "num_labels = len(label_names)\n",
    "label2id = {name: i for i, name in enumerate(label_names)}\n",
    "id2label = {i: name for i, name in enumerate(label_names)}\n",
    "print(f'Detected Labels ({num_labels}): {id2label}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1244738",
   "metadata": {},
   "source": [
    "## Load Processor and Model\n",
    "Load the image processor and the Vision Transformer model.\n",
    "\n",
    "## 5. Model and Processor Initialization\n",
    "We use a pre-trained Vision Transformer (ViT) model, a powerful AI that understands images. Python lets us:\n",
    "- Load the model and processor with one line of code.\n",
    "- Adapt the model for our specific task (number of labels).\n",
    "\n",
    "This step shows transfer learning, where we use knowledge from a model trained on millions of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569a6dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = AutoImageProcessor.from_pretrained(CHECKPOINT)\n",
    "model = ViTForImageClassification.from_pretrained(\n",
    "    CHECKPOINT,\n",
    "    num_labels=num_labels,\n",
    "    label2id=label2id,\n",
    "    id2label=id2label,\n",
    "    problem_type='single_label_classification'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9cfe6f",
   "metadata": {},
   "source": [
    "## Preprocess Function\n",
    "Resize images and prepare them for the model.\n",
    "\n",
    "## 6. Preprocessing Images\n",
    "AI models need images in a specific format. We:\n",
    "- Resize images to the right size (224x224 pixels).\n",
    "- Convert them to tensors (arrays of numbers) for the model.\n",
    "\n",
    "Python functions make it easy to automate this for every image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d5e4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(example):\n",
    "    image = example['image'].convert('RGB').resize((TARGET_RESOLUTION, TARGET_RESOLUTION))\n",
    "    inputs = processor(images=image, return_tensors='pt')\n",
    "    example['pixel_values'] = inputs['pixel_values'][0]\n",
    "    return example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15e735b",
   "metadata": {},
   "source": [
    "## Apply Preprocessing and Format Setting\n",
    "Process all images and set the dataset format for training.\n",
    "\n",
    "## 7. Dataset Preprocessing\n",
    "We apply our preprocessing function to every image in the dataset. Python's `map` function makes this efficient and fast.\n",
    "- The dataset is now ready for training.\n",
    "- We set the format so PyTorch can use it directly.\n",
    "\n",
    "This step is crucial for preparing data for machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2cbcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(preprocess, batched=False)\n",
    "dataset.set_format(type='torch', columns=['pixel_values', 'label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c63e550",
   "metadata": {},
   "source": [
    "## Training Setup\n",
    "Define metrics and training arguments.\n",
    "\n",
    "## 8. Metrics Definition\n",
    "To measure how well our AI is learning, we use metrics:\n",
    "- **Accuracy**: How many predictions are correct.\n",
    "- **F1 Score**: Balances accuracy for each class, useful for uneven data.\n",
    "\n",
    "Python functions let us calculate these automatically during training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c809cf47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    return {\n",
    "        'accuracy': accuracy_score(labels, preds),\n",
    "        'f1': f1_score(labels, preds, average='weighted')\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86fd1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    eval_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    num_train_epochs=10,\n",
    "    learning_rate=5e-5,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    remove_unused_columns=False,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='f1',\n",
    "    max_grad_norm=1.0,\n",
    "    lr_scheduler_type='cosine',\n",
    "    warmup_ratio=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3057594",
   "metadata": {},
   "source": [
    "## Training Arguments\n",
    "Set up how the model will learn.\n",
    "\n",
    "## 9. Training Arguments Setup\n",
    "We configure how the AI will learn:\n",
    "- **Batch Size**: Number of images processed at once.\n",
    "- **Epochs**: How many times the AI sees the whole dataset.\n",
    "- **Learning Rate**: How quickly the AI updates its knowledge.\n",
    "- **Early Stopping**: Stops training if no improvement is seen.\n",
    "\n",
    "Python makes it easy to set these parameters for experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308e5f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset['train'],\n",
    "    eval_dataset=dataset['validation'],\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138c36c0",
   "metadata": {},
   "source": [
    "## Define Trainer\n",
    "Set up the Trainer with model, arguments, datasets, and callbacks.\n",
    "\n",
    "## 10. Trainer Initialization\n",
    "The `Trainer` class from Hugging Face simplifies training:\n",
    "- Handles the training loop, evaluation, and saving.\n",
    "- Uses our model, data, metrics, and settings.\n",
    "- Supports callbacks like early stopping.\n",
    "\n",
    "This is a great example of how Python and modern libraries make AI development accessible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f45c46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Starting training...')\n",
    "trainer.train()\n",
    "trainer.save_model(f'{OUTPUT_DIR}/final_model')\n",
    "processor.save_pretrained(f'{OUTPUT_DIR}/final_model')\n",
    "print('Training complete and best model saved.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88728b8",
   "metadata": {},
   "source": [
    "## Train the Model\n",
    "Start training and save the best model.\n",
    "\n",
    "## 11. Model Training\n",
    "We start the training process:\n",
    "- The AI model learns from the training images.\n",
    "- It checks its progress on the validation set.\n",
    "- The best version is saved for future use.\n",
    "\n",
    "This step is where the AI actually learns to spot fake images, using Python code to control the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8877055b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'test' in dataset:\n",
    "    print('Running final evaluation on the Test set...')\n",
    "    predictions = trainer.predict(dataset['test'])\n",
    "    metrics = compute_metrics(predictions)\n",
    "    print('Test Metrics:', metrics)\n",
    "    y_true = predictions.label_ids\n",
    "    y_pred = predictions.predictions.argmax(-1)\n",
    "    target_names = list(id2label.values())\n",
    "    print('--- Classification Report ---')\n",
    "    print(classification_report(y_true, y_pred, target_names=target_names, digits=4))\n",
    "else:\n",
    "    print(\"Warning: 'test' split not found in data. Skipping final evaluation.\")\n",
    "print('Script finished.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2176e53b",
   "metadata": {},
   "source": [
    "## Final Evaluation on Test Set\n",
    "Evaluate the model on the test set and print results.\n",
    "\n",
    "## 12. Model Saving\n",
    "After training, we save the model and processor:\n",
    "- This lets us reuse the AI without retraining.\n",
    "- Python makes saving and loading models simple.\n",
    "\n",
    "Saving is important for deploying AI in real-world applications.\n",
    "\n",
    "## 13. Final Evaluation\n",
    "We test the AI on new images it hasn't seen before:\n",
    "- Predicts if each image is real or fake.\n",
    "- Calculates accuracy and F1 score.\n",
    "- Prints a detailed report.\n",
    "\n",
    "This step shows how to measure AI performance and ensure it works well in practice."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
